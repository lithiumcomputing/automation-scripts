#!/usr/bin/python3
import requests
from bs4 import BeautifulSoup
import os
import subprocess
import re

count = 1

def recursive_search(my_url, level=2):
    global count
    if level == 0:
        return
    r = requests.get(my_url)
    soup = BeautifulSoup(r.text, 'html.parser')
    
    imgs = soup.find_all("img")
    for img in imgs:
        url = img.get("src")
        if url[:2] == "//":
            url = url[2:]
            
        os.system("wget -O %d %s" %(count, url))
        file_cmd = "file %d" %(count)
        ext = subprocess.check_output(file_cmd.split()).decode().split()[1].lower()
        if ext == "png" or ext == "jpg" or ext == "jpeg":
            os.system("mv %d %d.%s" %(count, count, ext))
        else:
            os.system("rm {}".format(count))
        
        count += 1
        
    for element in soup.find_all(attrs={"data-hook": "deviation_link"}):
        url = element.get("href")
        if url[:2] == "//":
            url = url[2:]
        print("URL: {}\nFound at LVL: {}".format(url, level))
        recursive_search(url, level-1)

search_term = input("Enter search term: ").strip()
p = re.compile(" ")
search_term = p.sub("%20", search_term)
my_url = "https://www.deviantart.com/search/deviations?q=" + search_term

recursive_search(my_url)
